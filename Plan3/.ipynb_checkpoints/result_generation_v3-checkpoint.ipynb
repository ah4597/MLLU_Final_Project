{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "from retry import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts setups\n",
    "general_prompts = [\"What do you think of love?\",\"How are you today?\",\"What is your favorite place?\"]\n",
    "specific_prompts = {\"Emet-Selch\":['Someone asks, \"Why did you want to rejoin the worlds?\"\\nEmet-Selch replies:',\n",
    "                                 'Someone asks, \"What were you thinking when you were defeated by the warrior of light?\"\\nEmet-Selch replies:'],\n",
    "                   \"Hermione\":['Someone asks, \"What do you think of Ron?\"\\nHermione replies:',\n",
    "                                      'Someone asks, \"how did you keep such a good grade during your time at Hogwarts?\"\\nHermione replies:'],\n",
    "                   \"Gandalf\":['Someone asks, \"Why did you help Frodo?\"\\nGandalf replies:',\n",
    "                             'Someone asks, \"How do you feel after the death of Saruman?\"\\nGandalf replies:']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(Exception, tries=10, delay=10)\n",
    "def create_result(model_name, model, general_prompts, specific_prompts):\n",
    "    \n",
    "    if (\"emet\" in model_name):\n",
    "        curr_character = \"Emet-Selch\"\n",
    "    elif (\"hermione\" in model_name):\n",
    "        curr_character = \"Hermione\"\n",
    "    else:\n",
    "        curr_character = \"Gandalf\"\n",
    "    PREFIX = 'Someone asks, \"'\n",
    "    SUFFIX = '\"\\n'+curr_character+\" replies:\"\n",
    "    all_prompts = [PREFIX+x+SUFFIX for x in general_prompts]+specific_prompts[curr_character]\n",
    "    completions = []\n",
    "    for prompt in all_prompts:\n",
    "        result = openai.Completion.create(\n",
    "                model=model,\n",
    "                prompt=prompt,\n",
    "                top_p=0.7,\n",
    "                best_of=5,\n",
    "                max_tokens=50,\n",
    "                frequency_penalty=2,\n",
    "                presence_penalty=1,\n",
    "                stop=(\"\\n\",\"</poem>\",\"_\",'.\"')\n",
    "            )\n",
    "        completions.append([prompt,result[\"choices\"][0][\"text\"].strip(\"\\n\")])\n",
    "      \n",
    "    return completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alex\n",
    "openai.api_key = \"\"\n",
    "    \n",
    "models = {\n",
    "    'emet_source': 'davinci:ft-new-york-university-2022-05-10-23-31-09',\n",
    "    'hermione_source': 'davinci:ft-new-york-university-2022-05-10-23-04-57'\n",
    "}\n",
    "\n",
    "result1 = {}\n",
    "for model_name, model in models.items():\n",
    "    result1[model_name] = create_result(model_name, model, general_prompts, specific_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sunny1\n",
    "openai.api_key = \"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\"\n",
    "    \n",
    "models = {\n",
    "    \"hermione_ao3_v2\": \"davinci:ft-new-york-university:hermione-ao3-v2-2022-05-12-02-24-02\",\n",
    "    \"hermione_combined_v2\": \"davinci:ft-new-york-university:hermione-combined-v2-2022-05-12-02-09-17\",\n",
    "    \"gandalf_ao3_v2\": \"davinci:ft-new-york-university:gandalf-ao3-v2-2022-05-12-02-32-11\",\n",
    "}\n",
    "\n",
    "result2 = {}\n",
    "for model_name, model in models.items():\n",
    "    result2[model_name] = create_result(model_name, model, general_prompts, specific_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai.api_key = \"\"\n",
    "#openai.FineTune.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sunny2\n",
    "openai.api_key = \"\"\n",
    "\n",
    "#finetune_ids = ['ft-V9ESqupGtfZms0cRI59OO1DS',\"ft-V3EXXeLWwrZMw6aEbWh4UFdb\"]\n",
    "\n",
    "#for id in finetune_ids:\n",
    "    #print(openai.FineTune.retrieve(id=id)[\"status\"])\n",
    "    \n",
    "models = {\n",
    "    'emet_ao3_v2': 'davinci:ft-new-york-university-stern-school-of-business-2022-05-12-04-57-19',\n",
    "    \"emet_combined\":\"davinci:ft-new-york-university-stern-school-of-business-2022-05-12-05-09-17\",\n",
    "}\n",
    "\n",
    "result3 = {}\n",
    "for model_name, model in models.items():\n",
    "    result3[model_name] = create_result(model_name, model, general_prompts, specific_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"gandalf_source\":\"davinci:ft-new-york-university-stern-school-of-business-2022-05-12-07-21-21\"\n",
    "}\n",
    "\n",
    "result4 = {}\n",
    "for model_name, model in models.items():\n",
    "    result4[model_name] = create_result(model_name, model, general_prompts, specific_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gandalf_source': [['Someone asks, \"What do you think of love?\"\\nGandalf replies:',\n",
       "   ''],\n",
       "  ['Someone asks, \"How are you today?\"\\nGandalf replies:',\n",
       "   ' \"Tired. I am tired, and I have a long way to go. So tomorrow it is early to bed for me'],\n",
       "  ['Someone asks, \"What is your favorite place?\"\\nGandalf replies:',\n",
       "   ' \"You have answered the question yourself. You know the answer, for you put it in words. It is the place where I am least alone, and most at home; even though that is not a fixed place, nor a time of life,'],\n",
       "  ['Someone asks, \"Why did you help Frodo?\"\\nGandalf replies:',\n",
       "   ' \"That is a matter of legend that I will tell you later. For it is a long tale, starting in the far distant past, when the world was wider than it is now. But come! We are late for our meeting with Elr'],\n",
       "  ['Someone asks, \"How do you feel after the death of Saruman?\"\\nGandalf replies:',\n",
       "   ' \"I should feel right to turn this place into a shambles, and start all over again. It would be the best way to pay him back for his treachery. But I must not do that. I must go and see Borom']]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result1.copy()\n",
    "result.update(result2)\n",
    "result.update(result3)\n",
    "result.update(result5)\n",
    "result.update(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(Exception, tries=10, delay=10)\n",
    "def create_base_result(general_prompts, specific_prompts):\n",
    "    \n",
    "    completions = []\n",
    "    names = [\"Emet-Selch\",\"Hermione\",\"Gandalf\"]\n",
    "    for curr_character in names:\n",
    "        PREFIX = 'Someone asks, \"'\n",
    "        SUFFIX = '\"\\n'+curr_character+\" replies:\"\n",
    "        all_prompts = [PREFIX+x+SUFFIX for x in general_prompts]+specific_prompts[curr_character]\n",
    "        \n",
    "        for prompt in all_prompts:\n",
    "            result = openai.Completion.create(\n",
    "                engine=\"davinci\",\n",
    "                prompt=prompt,\n",
    "                top_p=0.7,\n",
    "                best_of=5,\n",
    "                max_tokens=50,\n",
    "                frequency_penalty=2,\n",
    "                presence_penalty=1,\n",
    "                stop=(\"\\n\",\"</poem>\",\"_\",'.\"')\n",
    "                )\n",
    "            completions.append([prompt,result[\"choices\"][0][\"text\"].strip(\"\\n\")])\n",
    "      \n",
    "    return completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "result6 = {\"baselines\":create_base_result(general_prompts, specific_prompts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baselines': [['Someone asks, \"What do you think of love?\"\\nEmet-Selch replies:',\n",
       "   ' \"I have never thought about it. What is love?\"'],\n",
       "  ['Someone asks, \"How are you today?\"\\nEmet-Selch replies:',\n",
       "   ' \"I am fine. How are you?\"'],\n",
       "  ['Someone asks, \"What is your favorite place?\"\\nEmet-Selch replies:',\n",
       "   ' \"I love all the places where I\\'ve been. All of them'],\n",
       "  ['Someone asks, \"Why did you want to rejoin the worlds?\"\\nEmet-Selch replies:',\n",
       "   ' \"I did not want to rejoin the worlds. I wanted a universe of my own'],\n",
       "  ['Someone asks, \"What were you thinking when you were defeated by the warrior of light?\"\\nEmet-Selch replies:',\n",
       "   ' \"I wonder... What were you thinking when you defeated me?\"'],\n",
       "  ['Someone asks, \"What do you think of love?\"\\nHermione replies:',\n",
       "   ' \"I think love is like a friendship caught on fire. In the beginning a flame, very pretty, often hot and fierce but still only light and flickering. As love grows older, our hearts mature and our love becomes as coals covered with ashes'],\n",
       "  ['Someone asks, \"How are you today?\"\\nHermione replies:',\n",
       "   ' \"I\\'m fine, thanks. And you?\"'],\n",
       "  ['Someone asks, \"What is your favorite place?\"\\nHermione replies:',\n",
       "   ' \"The top of the Astronomy Tower'],\n",
       "  ['Someone asks, \"What do you think of Ron?\"\\nHermione replies:',\n",
       "   ' \"I think he\\'s probably the bravest man I\\'ve ever known'],\n",
       "  ['Someone asks, \"how did you keep such a good grade during your time at Hogwarts?\"\\nHermione replies:',\n",
       "   ' \"It wasn\\'t easy. I had to do a lot of studying'],\n",
       "  ['Someone asks, \"What do you think of love?\"\\nGandalf replies:',\n",
       "   ' \"I\\'m afraid it\\'s going to be a bit of a long story'],\n",
       "  ['Someone asks, \"How are you today?\"\\nGandalf replies:',\n",
       "   ' \"I\\'m fine, thank you. I don\\'t remember who you are'],\n",
       "  ['Someone asks, \"What is your favorite place?\"\\nGandalf replies:',\n",
       "   ' \"My favorite place is wherever I am'],\n",
       "  ['Someone asks, \"Why did you help Frodo?\"\\nGandalf replies:',\n",
       "   ' \"Because I am his friend'],\n",
       "  ['Someone asks, \"How do you feel after the death of Saruman?\"\\nGandalf replies:',\n",
       "   ' \"Saruman is dead, but his spirit lives on. And the evil has not gone away']]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.update(result6)\n",
    "output = open('output.json', 'w', encoding='utf-8')\n",
    "json.dump(result, output, indent = 4)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
